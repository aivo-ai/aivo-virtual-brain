# AIVO Inference Gateway - Environment Configuration Template
# S2-01 Implementation: Multi-provider AI inference service

# =============================================================================
# SERVICE CONFIGURATION
# =============================================================================
ENVIRONMENT=development
PORT=8000

# =============================================================================
# OPENAI PROVIDER (REQUIRED)
# =============================================================================
# OpenAI API key (required for OpenAI provider)
OPENAI_API_KEY=your-openai-api-key-here

# Optional: Override OpenAI endpoint
# OPENAI_BASE_URL=https://api.openai.com/v1

# Optional: OpenAI organization ID
# OPENAI_ORGANIZATION=your-org-id

# Optional: Request timeout in seconds
# OPENAI_TIMEOUT=60

# =============================================================================
# VERTEX AI PROVIDER (OPTIONAL)
# =============================================================================
# Set to "true" to enable Vertex AI Gemini provider
ENABLE_VERTEX=false

# Google Cloud project ID
# VERTEX_PROJECT=your-gcp-project-id

# Vertex AI location/region
# VERTEX_LOCATION=us-central1

# Path to service account JSON file
# VERTEX_SERVICE_ACCOUNT_PATH=/path/to/service-account.json

# =============================================================================
# AWS BEDROCK PROVIDER (OPTIONAL)
# =============================================================================
# Set to "true" to enable AWS Bedrock Anthropic provider
ENABLE_BEDROCK=false

# AWS credentials
# AWS_ACCESS_KEY_ID=your-aws-access-key
# AWS_SECRET_ACCESS_KEY=your-aws-secret-key

# AWS region
# AWS_REGION=us-east-1

# =============================================================================
# PII SCRUBBING CONFIGURATION
# =============================================================================
# PII scrubbing mode: mask, hash, remove
PII_SCRUB_MODE=mask

# =============================================================================
# SECURITY CONFIGURATION
# =============================================================================
# CORS allowed origins (comma-separated)
ALLOWED_ORIGINS=*

# Trusted hosts for production (comma-separated)
# TRUSTED_HOSTS=yourdomain.com,api.yourdomain.com

# =============================================================================
# OBSERVABILITY CONFIGURATION
# =============================================================================
# OpenTelemetry OTLP endpoint
# OTLP_ENDPOINT=http://otel-collector:4317

# =============================================================================
# EXAMPLE VALUES FOR DEVELOPMENT
# =============================================================================
# Copy this file to .env and update with your actual values

# Development example:
# OPENAI_API_KEY=sk-your-key-here
# ENABLE_VERTEX=false
# ENABLE_BEDROCK=false
# PII_SCRUB_MODE=mask
# ENVIRONMENT=development

# Production example:
# OPENAI_API_KEY=sk-prod-key-here
# ENABLE_VERTEX=true
# VERTEX_PROJECT=my-prod-project
# VERTEX_SERVICE_ACCOUNT_PATH=/app/vertex-sa.json
# ENABLE_BEDROCK=true
# AWS_ACCESS_KEY_ID=AKIAEXAMPLE
# AWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
# PII_SCRUB_MODE=remove
# ALLOWED_ORIGINS=https://yourapp.com,https://api.yourapp.com
# TRUSTED_HOSTS=yourapp.com,api.yourapp.com
# OTLP_ENDPOINT=https://otel.yourapp.com:4317
# ENVIRONMENT=production
