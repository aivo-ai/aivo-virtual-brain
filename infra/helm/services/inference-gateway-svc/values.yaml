# Inference Gateway Service specific configuration
aivo-service:
  # Image configuration
  image:
    tag: "latest"
  
  # Service configuration
  service:
    port: 8080
    targetPort: 8080
  
  # Ingress configuration
  ingress:
    enabled: true
    annotations:
      nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
      nginx.ingress.kubernetes.io/proxy-send-timeout: "300"
      nginx.ingress.kubernetes.io/client-max-body-size: "100m"
    hosts:
      - host: inference.aivo.ai
        paths:
          - path: /
            pathType: Prefix
    tls:
      - secretName: inference-aivo-tls
        hosts:
          - inference.aivo.ai
  
  # Resource configuration - Higher requirements for AI workloads
  resources:
    requests:
      cpu: 500m
      memory: 1Gi
    limits:
      cpu: 2000m
      memory: 4Gi
  
  # Autoscaling - More aggressive for AI inference
  autoscaling:
    enabled: true
    minReplicas: 3
    maxReplicas: 20
    targetCPUUtilizationPercentage: 60
    targetMemoryUtilizationPercentage: 70
    behavior:
      scaleDown:
        stabilizationWindowSeconds: 300
        policies:
          - type: Percent
            value: 25
            periodSeconds: 60
      scaleUp:
        stabilizationWindowSeconds: 0
        policies:
          - type: Percent
            value: 100
            periodSeconds: 15
          - type: Pods
            value: 5
            periodSeconds: 15
        selectPolicy: Max
  
  # Vault configuration
  vault:
    enabled: true
    role: "inference-gateway-svc"
    secrets:
      - secretPath: "secret/data/aivo/inference-gateway-svc"
        template: |
          {{- with secret "secret/data/aivo/inference-gateway-svc" -}}
          DATABASE_URL="{{ .Data.data.database_url }}"
          REDIS_URL="{{ .Data.data.redis_url }}"
          OPENAI_API_KEY="{{ .Data.data.openai_api_key }}"
          ANTHROPIC_API_KEY="{{ .Data.data.anthropic_api_key }}"
          HUGGINGFACE_API_KEY="{{ .Data.data.huggingface_api_key }}"
          MODEL_REGISTRY_URL="{{ .Data.data.model_registry_url }}"
          MODEL_REGISTRY_AUTH="{{ .Data.data.model_registry_auth }}"
          RATE_LIMIT_REDIS_URL="{{ .Data.data.rate_limit_redis_url }}"
          {{- end }}
  
  # Environment variables
  env:
    - name: NODE_ENV
      value: "production"
    - name: PORT
      value: "8080"
    - name: LOG_LEVEL
      value: "info"
    - name: MAX_CONCURRENT_REQUESTS
      value: "100"
    - name: REQUEST_TIMEOUT
      value: "300000"
    - name: RATE_LIMIT_WINDOW
      value: "3600"
    - name: RATE_LIMIT_MAX
      value: "1000"
  
  # Health checks with longer timeouts for AI processing
  livenessProbe:
    httpGet:
      path: /health
      port: http
    initialDelaySeconds: 60
    periodSeconds: 15
    timeoutSeconds: 10
    failureThreshold: 3
  
  readinessProbe:
    httpGet:
      path: /ready
      port: http
    initialDelaySeconds: 30
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 5
  
  # High priority for critical AI inference
  priorityClassName: aivo-critical
  
  # Network policy - needs external AI provider access
  networkPolicy:
    enabled: true
    ingress:
      - from:
          - namespaceSelector:
              matchLabels:
                name: ingress-nginx
        ports:
          - protocol: TCP
            port: 8080
      - from:
          - podSelector:
              matchLabels:
                app.kubernetes.io/component: service
        ports:
          - protocol: TCP
            port: 8080
    egress:
      - to: []
        ports:
          - protocol: TCP
            port: 53
          - protocol: UDP
            port: 53
      - to: []
        ports:
          - protocol: TCP
            port: 8200  # Vault
      - to: []
        ports:
          - protocol: TCP
            port: 5432  # PostgreSQL
      - to: []
        ports:
          - protocol: TCP
            port: 6379  # Redis
      - to: []
        ports:
          - protocol: TCP
            port: 443   # HTTPS for AI providers (OpenAI, Anthropic, etc.)
      - to: []
        ports:
          - protocol: TCP
            port: 80    # HTTP for some AI providers
